<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Chapter&nbsp;3.&nbsp;Examples</title><meta name="generator" content="DocBook XSL Stylesheets V1.70.1"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="examples"></a>Chapter&nbsp;3.&nbsp;Examples</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#d0e10">Using Wordlists</a></span></dt><dt><span class="section"><a href="#d0e66">Searching by Keyword</a></span></dt><dt><span class="section"><a href="#d0e91">Filtering Content During Indexing</a></span></dt><dt><span class="section"><a href="#d0e117">Pruning/Refining Searches</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e134">Using Pruning Random Walk Subgraphs</a></span></dt><dt><span class="section"><a href="#d0e200">Pruning After Searching/Indexing</a></span></dt></dl></dd><dt><span class="section"><a href="#d0e216">Finding Similar Documents</a></span></dt><dt><span class="section"><a href="#d0e240">2D or 3D Layout Using LinLog</a></span></dt><dt><span class="section"><a href="#d0e251">Exporting to GraphViz</a></span></dt><dt><span class="section"><a href="#d0e296">Agglomerative Clustering</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e323">Using Edge Weights</a></span></dt><dt><span class="section"><a href="#d0e336">Using Euclidian Distance</a></span></dt></dl></dd></dl></div><p>
        This chapter contains a number of examples using the <span class="application">Semantic Engine</span>
        for showcasing its functionality beyond simple indexing and searching. 
    </p><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e10"></a>Using Wordlists</h2></div></div></div><p>
            If you have performed a couple searches on an index, you may have noticed that the terms
            returned look a little weird. For example the term <span class="emphasis"><em>conspiracy</em></span> may be returned
            as <span class="emphasis"><em>conspiraci</em></span> or <span class="emphasis"><em>genlty</em></span> as <span class="emphasis"><em>gentl</em></span>. This occurs
            because words in the <span class="application">Semantic Engine</span> are stemmed. This means that if you search
            for any of the words <span class="emphasis"><em>knit</em></span>, <span class="emphasis"><em>knits</em></span>, <span class="emphasis"><em>knitting</em></span> or
            <span class="emphasis"><em>knitted</em></span> they will all resolve to the same term: <span class="emphasis"><em>knit</em></span>. This is done
            so that searching for singular nouns, for example, does not exclude the plurals of the same noun. 
        </p><p>
            Naturally, this is relatively unsightly for a human reader. A wordlist is stored with the index which
            maps the stemmed versions of words back to their un-stemmed version. Since multiple words will stem to the
            same stemmed word, the most frequent un-stemmed word will be in the wordlist. Retrieving the wordlist is a 
            simple process and is shown below.
        </p><p>
            Assuming you have already created a <code class="code">SEGraph</code> or <code class="code">SESubgraph</code> object named <code class="code">graph</code>,
            the following code will allow you to retrieve the wordlist and lookup terms.
        </p><pre class="programlisting">
        
#include &lt;semantic/search.hpp&gt;            // for unserialize_wordlist

std::map&lt;std::string, std::string&gt; myWordlist;
myWordlist = unserialize_wordlist(graph.get_meta_value("wordlist"));
std::string myDisplayWord = myWordlist[someStemmedWord];
        
        </pre><p>
            <span class="emphasis"><em>NOTE:</em></span> stemmed words are always stored in lowercase in the index.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e66"></a>Searching by Keyword</h2></div></div></div><p>
            Searching by keyword is as easy as calling the <code class="code">keyword(std::string)</code> method on the
            <code class="code">semantic::search</code> object. Refer to ??? for how to set up
            the <code class="code">semantic::search</code> object. Then just replace the line
        </p><pre class="programlisting">
search_helper.semantic("my query string");
        </pre><p>
            with
        </p><pre class="programlisting">
search_helper.keyword("my query string");
        </pre><p>
            This will fetch only those documents that contain at least one of the search terms. No expanded
            recall will be performed, and hence no list of "top terms" will be returned, either.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e91"></a>Filtering Content During Indexing</h2></div></div></div><p>
            As was seen in ???, it is easy to throw files at the indexer class. It is often
            important to perform some cleaning, scrubbing, alteration, pruning or refinement of the textual
            data passed to the indexer. Some things you might want to do are: only choose words that are at least
            three letters long, cap word length at <code class="code">15</code> letters, add a blacklist (stoplist), ignore
            words that are riddled with numbers, and so on. 
        </p><p>
            The code section below installs some basic word filters into the <code class="code">semantic::text_indexer</code> as 
            seen in ???:
        </p><pre class="programlisting">
// blacklist_filter(std::set&lt;std::string&gt;) will ignore any words that appear in the
// set. use it with a stoplist to make for better search results.
indexer.add_word_filter(blacklist_filter(blacklist));
            
// too_many_numbers_filter(int n) will ignore "words" that have more than n
// digits in them.
indexer.add_word_filter(too_many_numbers_filter(6));
            
// minimum_length_filter(int n) will ignore words shorter than n characters
indexer.add_word_filter(minimum_length_filter(3));
            
// maximum_word_length_filter(int n) will ignore words longer than n characters
indexer.add_word_filter(maximum_word_length_filter(15));
            
// maximum_phrase_length_filter(int n) will ignore phrases (like "The Empire State Building")
// if they are longer than n words. 
indexer.add_word_filter(maximum_phrase_length_filter(4));
            </pre><p>
            See <code class="filename">semantic/filter.hpp</code> for more information. 
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e117"></a>Pruning/Refining Searches</h2></div></div></div><p>
            It is possible (and often desirable) to prune or refine search results. The <span class="application">Semantic Engine</span>
            by default will give the broadest search results back (depending on the choice of <span class="emphasis"><em>Subgraph Policy</em></span>). 
            Especially for analysis, the graphs that the <span class="application">Semantic Engine</span> returns will be too highly
            connected to perform efficient analysis. So, a number of pruning helper methods exist. Some example are below, and more
            can be found in <code class="filename">semantic/pruning.hpp</code>.
        </p><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d0e134"></a>Using Pruning Random Walk Subgraphs</h3></div></div></div><p>
                Pruning Random Walk is a special <span class="emphasis"><em>Subgraph Policy</em></span> which aims to prune out irrelevant
                indexing data before the actual subgraph creation begins. We have found this to dramatically increase
                the relevance of returned results, while also dramatically decreasing the search time. The pruning
                random walk subgraph policy can be found in: <code class="filename">semantic/subgraph/pruning_random_walk.hpp</code>.
            </p><p>
                The policy is tuned by accessing the following methods on the graph object: <code class="code">set_depth(int)</code>, 
                <code class="code">set_trials(int)</code>, <code class="code">keep_only_top_edges(float)</code> and <code class="code">set_seed(unsigned long)</code>.
            </p><p>
                <span class="emphasis"><em>set_depth(int)</em></span> sets the maximum search depth on the graph. The random walk algorithms
                perform a walk down to a certain depth from the "start node", which is usually a search term or document. 
                A good number seems to be <code class="code">4</code>. 
            </p><p>
                <span class="emphasis"><em>set_trials(int)</em></span> sets the number of "walk trials". The random walk algorithms work
                by choosing a weighted-random (meaning that higher-weighted edges have more of a chance of getting hit) edge
                and walking to that vertex. This is repeated to a specified depth (using <code class="code">set_depth()</code>) and 
                overall performed a set number of times (called trials). <code class="code">100</code> is a good starting number for
                <code class="code">set_trials()</code>.
            </p><p>
                <span class="emphasis"><em>keep_only_top_edges(float)</em></span> defines what level of pruning should be performed before
                the random walks. A value of <code class="code">1.0</code> will perform no pruning whatsoever, whereas a value of <code class="code">0.5</code>
                will keep the top weighted <code class="code">50%</code> of the edges on each vertex. This means that if there is one edge that is
                weighted more heavily than all the other edges combined, it is the only edge that will be considered for random walking. 
                Here, smaller values will restrict the results while larger ones will expand the results. It can be thought of as a measure
                of keeping results very relevant to the search query or branching them out a bit.
            </p><p>
                <span class="emphasis"><em>set_seed(unsigned long)</em></span> allows you to seed the random number generator used by the random
                walk algorithms. For example, if you consistently want the exact same search results back every time you search
                for the same words, you should seed it to a pre-specified number. By default it is seeded to the current time
                on your computer. 
            </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d0e200"></a>Pruning After Searching/Indexing</h3></div></div></div><p>It is possible to do pruning operations on the graph after creating one by performing a search
            or indexing a number of files. Here are some example pruning algorithms and how to apply them to an
            existing graph object, <code class="code">graph</code>.</p><pre class="programlisting">
                
// This method will do the same pruning operation as the Pruning Random Walk. Don't expect
// a search with this pruning applied to be the same as performing the pruning from *within*
// the Pruning Random Walk policy.
keep_top_n_percent_of_graph_edges_weighted(graph, 0.2, boost::make_assoc_property_map(my_weight_map));

// This method will make sure that the graph has symmetry: that an edge in one direction
// exists in the other, and that the WeightMap reflects this information.
ensure_graph_symmetry(graph, boost::make_assoc_property_map(my_weight_map));
            
            </pre><p>
                Further examples can be found in <code class="filename">semantic/pruning.hpp</code>.
            </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e216"></a>Finding Similar Documents</h2></div></div></div><p>
            Say you have a document or two and you want to find documents similar to those. Well it's easy.
            You can use the <code class="code">semantic::search</code> class (as was seen in the example in ???)
            but use the <code class="code">similar()</code> method instead of the <code class="code">semantic()</code> or <code class="code">keyword()</code> methods.
        </p><p>
            The index is a little different, as the following two examples illustrate:
        </p><pre class="programlisting">
            
// if we previously indexed '/my/document.txt'
results = search_helper.similar("/my/document.txt");

// if we have a vector or set of document names in my_container
results = search_helper.similar(my_container.begin(), my_container.end());
            
        </pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e240"></a>2D or 3D Layout Using LinLog</h2></div></div></div><p>
            This section shows how the <span class="application">Semantic Engine</span> can be used to do visual layouts of
            indexing data. The LinLog algorithm was developed by Andreas Noack and was re-written to apply it to our
            graphs. The following code block shows how to get a list of 2D or 3D coordinates from a graph (could be from
            search results or an entire index). 
        </p><pre class="programlisting">
            
#include &lt;semantic/analysis/linlog.hpp&gt;

typedef semantic::analysis::linlog_traits&lt;MyGraph, 
    boost::associative_property_map&lt;MyWeightMapType&gt; &gt; traits;

// let's initialize the necessary data for layout calculation
traits::point_map_type positions;
            
// make a random generator (your choice)
some_rand_functor_type some_rand_functor;

// initialize the position map
BGL_FORALL_VERTICES(u, graph, MyGraph) {
    traits::point p;
    p.set_rand(some_rand_functor);
    // for 2d applications, set z = 0
    // p.z() = 0;
    positions[u] = p; 
}
            
// ok now we're ready to perform the actual calculations, running 200 iterations.
// the more iterations you run, the more the layout will settle.
semantic::analysis::linlog_layout(graph, boost::make_assoc_property_map(my_weight_map), 200, positions);

// draw the nodes somewhere, or something
BGL_FORALL_VERTICES(u, graph, MyGraph) {
    std::cout &lt;&lt; "vertex " &lt;&lt; u &lt;&lt; " is at " &lt;&lt; positions[u] &lt;&lt; std::endl;
}
            
        </pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e251"></a>Exporting to GraphViz</h2></div></div></div><p>
            We will explore how to export an <code class="code">SEGraph</code> to <span class="application">GraphViz</span>. Turns
            out it's exceedingly easy as <span class="emphasis"><em>BOOST</em></span> supplies a <span class="application">GraphViz</span>
            export/import facility.
        </p><p>
            The interface we are going to use is this one, supplied by <span class="emphasis"><em>BOOST</em></span>:
        </p><pre class="programlisting">
            
template &lt; typename VertexListGraph, typename VertexPropertyWriter, typename EdgePropertyWriter &gt;
void
write_graphviz(std::ostream&amp; out, const VertexListGraph&amp; g, 
    VertexPropertyWriter vpw, EdgePropertyWriter epw);
            
        </pre><p>
            We are going to have to write the <code class="code">VertexPropertyWriter</code> and the <code class="code">EdgePropertyWriter</code>:
        </p><pre class="programlisting">
            
struct OurEdgePropertyWriter {
    OurEdgePropertyWriter(MyGraph &amp;g_) : g(g_) {}
    template &lt;class Edge&gt;
    void operator() (std::ostream &amp;out, Edge e) {
        out &lt;&lt; "[weight=" &lt;&lt; g[e].strength &lt;&lt; "]";
    }
    
    MyGraph &amp;g;
};

struct OurVertexPropertyWriter {
    OurVertexPropertyWriter(MyGraph &amp;g_) : g(g_) {}
    template &lt;class Vertex&gt;
    void operator() (std::ostream &amp;out, Vertex u) {
        out &lt;&lt; "[label=" &lt;&lt; g[u].content &lt;&lt; "]";
    }

    MyGraph &amp;g;
};
            
        </pre><p>
            Putting these parts together, using a graph previously created by your method of choice:
        </p><pre class="programlisting">
            
#include &lt;fstream&gt;
#include &lt;boost/graph/graphviz.hpp&gt;
            
std::ofstream out_file("my_file.dot");

boost::write_graphviz(out_file, graph, OurVertexPropertyWriter(graph), ourEdgePropertyWriter(graph));
            
        </pre><p>
            See <code class="filename">boost/graph/graphviz.hpp</code> for more information.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e296"></a>Agglomerative Clustering</h2></div></div></div><p>
            Agglomerative Clustering uses the following technique:
            </p><div class="orderedlist"><ol type="1"><li>
                    Choose the two nodes closest together, combine them into one cluster.
                </li><li>
                    Recalculate distances between this new cluster and existing nodes/clusters.
                </li><li>
                    Rinse and repeat.
                </li></ol></div><p>
        </p><p>
            The <span class="application">Semantic Engine</span> provides methods for the construction of
            Minimum/Maximum Spanning Trees and Dendrograms, which live in the <code class="code">semantic</code>
            namespace. These two components are necessary for agglomerative clustering.
        </p><pre class="programlisting">
            
template &lt;class Graph, class WeightMap, class OutputIterator&gt;
inline void minimum_weight_spanning_tree(Graph &amp;g, WeightMap w, OutputIterator out);
            
template &lt;class Graph, class EdgeIt, class WeightMap, class OutputIterator&gt;
inline void minimum_weight_spanning_tree(Graph &amp;g, EdgeIt edge_start, EdgeIt edge_end, WeightMap w, OutputIterator out);
            
template &lt;class Graph, class WeightMap, class OutputIterator&gt;
inline void maximum_weight_spanning_tree(Graph &amp;g, WeightMap w, OutputIterator out);
            
template &lt;class Graph, class EdgeIt, class WeightMap, class OutputIterator&gt;
inline void maximum_weight_spanning_tree(Graph &amp;g, EdgeIt edge_start, EdgeIt edge_end, WeightMap w, OutputIterator out);
            
        </pre><p>... and ...</p><pre class="programlisting">
            
template &lt;
    class Graph, 
    class MST, 
    class WeightMap, 
    class Dendrogram, 
    class DistanceCalculator&gt;
void dendrogram_from_distance_mst(Graph &amp;g, MST &amp;mst, WeightMap w, Dendrogram &amp;out, DistanceCalculator dist = DistanceCalculator());
            
template &lt;
    class Graph, 
    class MST, 
    class WeightMap, 
    class Dendrogram, 
    class DistanceCalculator&gt;
void dendrogram_from_similarity_mst(Graph &amp;g, MST &amp;mst, WeightMap w, Dendrogram &amp;out, DistanceCalculator dist = DistanceCalculator());
            
        </pre><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d0e323"></a>Using Edge Weights</h3></div></div></div><p>
                Stronger edge weights mean a stronger connection between two nodes. So this is not a "distance" measure,
                but more a similarity measure. So we are going to find a <code class="code">maximum_spanning_tree</code> and use the
                <code class="code">dendrogram_from_similarity_mst()</code> method as shown.
            </p><pre class="programlisting">
                
#include &lt;semantic/analysis/agglomerative_clustering/mst.hpp&gt;
#include &lt;semantic/analysis/agglomerative_clustering/dendrogram.hpp&gt;

std::vector&lt;semantic::se_graph_traits&lt;MyGraph&gt;::edge_descriptor&gt; my_mst;

semantic::maximum_weight_spanning_tree(
    graph, 
    boost::make_assoc_property_map(my_weight_map), 
    back_inserter(my_mst));

semantic::dendrogram&lt;MyGraph&gt; my_dendrogram;
semantic::dendrogram_from_similarity_mst(
    graph,
    my_mst,
    boost::make_assoc_property_map(my_weight_map),
    my_dendrogram,
    semantic::SingleLinkDistaneCalculator());
                
my_dendrogram.set_num_cluster(5);
std::map&lt;
    semantic::se_graph_traits&lt;MyGraph&gt;::vertex_descriptor,
    semantic::se_graph_traits&lt;MyGraph&gt;::vertices_size_type&gt; my_clusters;

my_dendrogram.get_clusters(inserter(my_clusters, my_clusters.begin()));

// or you can get vertices in the same cluster as one you already
// have:
semantic::se_graph_traits&lt;MyGraph&gt;::vertex_descriptor u = graph.vertices().first;
std::vector&lt;semantic::se_graph_traits&lt;MyGraph&gt;::vertex_descriptor&gt; my_list;

my_dendrogram.get_vertices_in_cluster_with(u, back_inserter(my_list));
                
            </pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d0e336"></a>Using Euclidian Distance</h3></div></div></div><p>
                You will see that it is not necessary to use the weight map as the only measure of
                distance/similarity between nodes. As an example we use the euclidian distance generated
                by a layout algorithm. We have a <code class="code">std::map</code> of vertices matched to a <code class="code">point</code>
                showing their location in space. 
            </p><p>
                This approach will be slightly different as the "edges" that we are going to use are
                in a sense imaginary, since they might not exist in the actual graph. We want to use the distance
                between two vertices as a measure of how <span class="emphasis"><em>different</em></span> they are (the farther apart,
                the greater the distance, the greater the dissimilarity). 
            </p><p>
                Since these "edges" don't actually exist, we will have to supply the algorithms with an 
                edge list, which we will acquire by building a distance map of every vertex to every other vertex.
            </p><pre class="programlisting">
                
typedef se_graph_traits&lt;MyGraph&gt;::vertex_pair_edge pair_edge; // a std::pair of vertex_descriptors
std::map&lt;pair_edge, double&gt; distance_map;
BGL_FORALL_VERTICES(u, graph, MyGraph) {
    BGL_FORALL_VERTICES(v, graph, MyGraph) {
        if (u == v) continue;
        // calculate the distance between u and v. since this is only going to be used
        // in comparison to other distances, we need not do the sqrt(), which is slow.
        pair_edge e1(u, v), e2(v, u);        // do both directions
        if (!distance_map.count(e1) || !distance_map.count(e2)) {
            distance_map[e1] = distance_map[e2] = position_map[u].dist2(position_map[v]);
        }
    }
}
                
            </pre><p>
                Now we have <code class="code">distance_map</code> and we need to create from it a <code class="code">minimum_weight_spanning_tree</code>.
            </p><pre class="programlisting">
                
std::vector&lt;pair_edge&gt; my_mst;
semantic::minimum_weight_spanning_tree(graph, extract_keys(distance_map.begin()), extract_keys(distance_map.end()),
    boost::make_assoc_property_map(distance_map), back_inserter(my_mst));
                
            </pre><p>
                The <code class="code">extract_keys()</code> macro can be found in <code class="filename">semantic/utility.hpp</code> and is used here
                to create an iterator of edges from the <code class="code">std::pair</code> data type of the <code class="code">distance_map</code>. Now
                we just create our dendrogram, like above.
            </p><pre class="programlisting">
                
semantic::dendrogram&lt;MyGraph&gt; my_dendrogram;
semantic::dendrogram_from_distance_mst(graph, my_mst, boost::make_assoc_property_map(distance_map),
    my_dendrogram, semantic::SingleLinkDistanceCalculator());
                
            </pre></div></div></div></body></html>